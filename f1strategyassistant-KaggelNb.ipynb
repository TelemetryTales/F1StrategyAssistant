{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Strategy Assistant – MVP\n",
    "\n",
    "This notebook demonstrates a GenAI assistant that helps F1 strategists decide when to pit, using real-time race data.\n",
    "\n",
    "---\n",
    "\n",
    "In Formula 1, deciding the optimal time for a pit stop is a complex and high-stakes challenge. Strategists must balance a wide range of factors — tyre wear, compound choice, weather, track conditions, and more — all while reacting to real-time developments like safety cars or opponent decisions. These decisions must be made quickly and under pressure, leaving room for human error.\n",
    "\n",
    "This project explores how a GenAI-powered assistant can support F1 strategists by:\n",
    "\n",
    "- Continuously analyzing race context based on numerical inputs.\n",
    "- Providing timely pit recommendations grounded in data.\n",
    "- Reducing cognitive load by automating data-driven decision-making.\n",
    "- Offering recalculated guidance when unexpected changes occur (e.g., strategy deviations, weather shifts).\n",
    "\n",
    "By offloading number-driven tasks to the AI, the human strategist can focus on elements influenced by competitor behavior and race psychology — areas where human judgment excels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Data Engineering and Model Training\n",
    "\n",
    "To begin, we install the `fastf1` library. This API gives us access to lap-by-lap telemetry and session data, which is essential for building a model that understands race dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:37.914276Z",
     "iopub.status.busy": "2025-04-20T14:22:37.913953Z",
     "iopub.status.idle": "2025-04-20T14:22:41.652720Z",
     "shell.execute_reply": "2025-04-20T14:22:41.651609Z",
     "shell.execute_reply.started": "2025-04-20T14:22:37.914253Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastf1 in /usr/local/lib/python3.11/dist-packages (3.5.3)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from fastf1) (3.7.5)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.23.1 in /usr/local/lib/python3.11/dist-packages (from fastf1) (1.26.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from fastf1) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from fastf1) (2.9.0.post0)\n",
      "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (from fastf1) (3.13.0)\n",
      "Requirement already satisfied: requests-cache>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from fastf1) (1.2.1)\n",
      "Requirement already satisfied: requests>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from fastf1) (2.32.3)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from fastf1) (1.15.2)\n",
      "Requirement already satisfied: timple>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fastf1) (0.1.8)\n",
      "Requirement already satisfied: websockets<14,>=10.3 in /usr/local/lib/python3.11/dist-packages (from fastf1) (13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.5.1->fastf1) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.5.1->fastf1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.5.1->fastf1) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.5.1->fastf1) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.5.1->fastf1) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.5.1->fastf1) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.5.1->fastf1) (3.2.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.23.1->fastf1) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.23.1->fastf1) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.23.1->fastf1) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.23.1->fastf1) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.23.1->fastf1) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.23.1->fastf1) (2.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.4.1->fastf1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.4.1->fastf1) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->fastf1) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->fastf1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->fastf1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->fastf1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->fastf1) (2025.1.31)\n",
      "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.11/dist-packages (from requests-cache>=1.0.0->fastf1) (25.3.0)\n",
      "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.11/dist-packages (from requests-cache>=1.0.0->fastf1) (24.1.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests-cache>=1.0.0->fastf1) (4.3.7)\n",
      "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.11/dist-packages (from requests-cache>=1.0.0->fastf1) (2.2.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.23.1->fastf1) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.23.1->fastf1) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.23.1->fastf1) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.23.1->fastf1) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.23.1->fastf1) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:41.654848Z",
     "iopub.status.busy": "2025-04-20T14:22:41.654532Z",
     "iopub.status.idle": "2025-04-20T14:22:41.660605Z",
     "shell.execute_reply": "2025-04-20T14:22:41.659401Z",
     "shell.execute_reply.started": "2025-04-20T14:22:41.654819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastf1 as ff1\n",
    "import fastf1.plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection \n",
    "\n",
    "We define a function `gpData(year, country, session)` that:\n",
    "\n",
    "- Loads session data for a given race.\n",
    "- Extracts lap-level data using FastF1.\n",
    "- Computes several additional features:\n",
    "  - **DeltaTime:** Lap-to-lap performance variation for each driver.\n",
    "  - **GapAhead:** Average time gap to the car ahead on each lap.\n",
    "  - **PosToLose:** How many positions a driver would likely lose if they pitted at that moment, based on the pit lane time loss and gaps ahead.\n",
    "  - **RemainingLaps:** Number of laps left in the race.\n",
    "- Builds the target series `pitting`, which indicates whether a car pitted on a given lap.\n",
    "\n",
    "The function returns:\n",
    "- A processed `DataFrame` with race features.\n",
    "- A binary `Series` as the prediction target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:41.662159Z",
     "iopub.status.busy": "2025-04-20T14:22:41.661711Z",
     "iopub.status.idle": "2025-04-20T14:22:41.683371Z",
     "shell.execute_reply": "2025-04-20T14:22:41.682474Z",
     "shell.execute_reply.started": "2025-04-20T14:22:41.662127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def gpData(year, country, session):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        year (int): The year of the race (e.g., 2023, 2024).\n",
    "        country (str): The country where the race is held (e.g., 'Saudi Arabia').\n",
    "        session (str): The session of the race (e.g., 'r' for race, 'q' for qualifying).\n",
    "\n",
    "    Returns:\n",
    "        race (DataFrame): A DataFrame containing lap-level data and derived features.\n",
    "        pitting (Series): A series indicating whether a pit stop occurred (1 for pit, 0 for no pit).\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the specified session using the FastF1 API\n",
    "    session = ff1.get_session(year, country, session)\n",
    "    session.load()\n",
    "\n",
    "    # Extract lap data and sort by lap number and position\n",
    "    laps = session.laps\n",
    "    laps.sort_values(by=['LapNumber', 'Position'], inplace=True)\n",
    "    laps.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Get weather data for the session\n",
    "    weather = laps.get_weather_data()\n",
    "\n",
    "    # Create the race DataFrame with relevant lap-level data\n",
    "    race = pd.DataFrame({\n",
    "        'LapNumber': laps['LapNumber'].values,\n",
    "        'Position': laps['Position'].values,\n",
    "        'Compound': laps['Compound'].values,\n",
    "        'TyreLife': laps['TyreLife'].values,\n",
    "        'TrackStatus': laps['TrackStatus'].map(lambda x: 1 if x == 4 else (2 if x == 6 else 0)),\n",
    "        'TrackTemp': weather['TrackTemp'].values,\n",
    "        'Rainfall': weather['Rainfall'].values.astype(int)\n",
    "    })\n",
    "\n",
    "\n",
    "    # Calculate the delta time between consecutive laps for each driver\n",
    "    lap_time_delta = pd.Series()\n",
    "\n",
    "    for i, driver in laps.groupby('Driver'):\n",
    "        delta =[]\n",
    "        delta = driver['LapTime'].dt.total_seconds().diff()\n",
    "        delta.fillna(0, inplace=True)\n",
    "        lap_time_delta = pd.concat([lap_time_delta, delta])\n",
    "\n",
    "    race['DeltaTime'] = lap_time_delta\n",
    "\n",
    "\n",
    "    # Calculate average distance to the driver ahead over a lap in seconds\n",
    "    gap = []\n",
    "    for i, l in laps.iterlaps():\n",
    "        dist = l.get_telemetry().DistanceToDriverAhead\n",
    "        speed = l.get_telemetry().Speed*3.6\n",
    "\n",
    "        gap.append((dist/speed).mean())\n",
    "\n",
    "    race['GapAhead'] = gap\n",
    "    race['GapAhead'].replace(np.inf,np.nan, inplace=True)\n",
    "    race['GapAhead'].fillna(0, inplace=True)\n",
    "\n",
    "    \n",
    "    # Add country of the race\n",
    "    race['Country'] = session.event.Country\n",
    "\n",
    "    \n",
    "    # Calculate the number of positions that would be lost if the driver pitted in that lap\n",
    "    lost_pos = []\n",
    "\n",
    "    for i,group in race.groupby('LapNumber'):\n",
    "        k = 0\n",
    "        for j in group.index:\n",
    "            if group.loc[j,'TrackStatus'] == 0:\n",
    "                pit_loss = pit_stop_cost[group.loc[j,'Country']]\n",
    "                \n",
    "            else :\n",
    "                pit_loss = pit_stop_cost_sc[group.loc[j,'Country']]\n",
    "\n",
    "            counter = 1\n",
    "            loss = 0\n",
    "            while (loss < pit_loss) & ((k+counter) < group.index.size):\n",
    "                loss += group.loc[j+counter,'GapAhead']\n",
    "                counter += 1\n",
    "\n",
    "            lost_pos.append(counter)\n",
    "            k += 1\n",
    "\n",
    "    race['PosToLose'] = lost_pos\n",
    "\n",
    "    \n",
    "    race['TotalLaps'] = laps['LapNumber'].max()\n",
    "    race['RemainingLaps'] = race['TotalLaps'] - race['LapNumber']\n",
    "\n",
    "    \n",
    "    laps.sort_values(by=['Driver', 'LapNumber'], inplace=True)\n",
    "    \n",
    "   # Define the condition when a car is making a pit stop\n",
    "    pit_stop_condition = (\n",
    "    (laps['PitInTime'].notna()) &\n",
    "    (laps['TyreLife'] >= laps['TyreLife'].shift(-1)) &\n",
    "    (laps['PitOutTime'].shift(-1).notna())\n",
    "    )\n",
    "\n",
    "    # Create a target series for pit stop (1 for pit, 0 for no pit)\n",
    "    pitting = pd.Series(np.where(pit_stop_condition, 1, 0))\n",
    "    pitting.index = laps.index\n",
    "    pitting.sort_index(inplace=True)\n",
    "\n",
    "    return race, pitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate potential position loss due to pitting, we define dictionaries for pit stop loss in seconds for both normal conditions and for safety car or virtual safety car conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:41.685709Z",
     "iopub.status.busy": "2025-04-20T14:22:41.685420Z",
     "iopub.status.idle": "2025-04-20T14:22:41.703498Z",
     "shell.execute_reply": "2025-04-20T14:22:41.702481Z",
     "shell.execute_reply.started": "2025-04-20T14:22:41.685689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pit_stop_cost={\n",
    "    'Saudi Arabia': 0.2\n",
    "}\n",
    "\n",
    "pit_stop_cost_sc={\n",
    "    'Saudi Arabia': 0.11\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure quick iteration and testing, our final dataset will consist of data from a single circuit across two different seasons. This decision was made because processing a single race can take over 30 minutes. By focusing on just one circuit, we maintain a consistent environment while still capturing enough variability for meaningful learning and experimentation.\n",
    "\n",
    "We chose the 2023 and 2024 seasons of the Saudi Arabian Grand Prix, as it is a shorter circuit. Additionally, it is the next race in the 2025 season, which will provide an opportunity to test the agent live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:41.705072Z",
     "iopub.status.busy": "2025-04-20T14:22:41.704683Z",
     "iopub.status.idle": "2025-04-20T14:22:41.720312Z",
     "shell.execute_reply": "2025-04-20T14:22:41.719416Z",
     "shell.execute_reply.started": "2025-04-20T14:22:41.705044Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "saudi23, saudi23_target = gpData(2023, 'Saudi Arabia', 'r')\n",
    "saudi24, saudi24_target = gpData(2024, 'Saudi Arabia', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data engineering\n",
    "\n",
    "We prepare the data for the model by combining race data from two different years, cleaning up missing values, encoding categorical variables, and dropping unnecessary columns. This ensures the data is ready for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:41.721752Z",
     "iopub.status.busy": "2025-04-20T14:22:41.721407Z",
     "iopub.status.idle": "2025-04-20T14:22:41.739308Z",
     "shell.execute_reply": "2025-04-20T14:22:41.738286Z",
     "shell.execute_reply.started": "2025-04-20T14:22:41.721719Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Combine lap data from the 2 races.\n",
    "lapData = pd.concat([saudi23, saudi24], ignore_index=True)\n",
    "target = pd.concat([saudi23_target, saudi24_target], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:41.740549Z",
     "iopub.status.busy": "2025-04-20T14:22:41.740293Z",
     "iopub.status.idle": "2025-04-20T14:22:41.757445Z",
     "shell.execute_reply": "2025-04-20T14:22:41.756488Z",
     "shell.execute_reply.started": "2025-04-20T14:22:41.740529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing \"Position\" values.\n",
    "rows_to_drop = lapData[lapData[\"Position\"].isna()].index\n",
    "lapData = lapData.drop(rows_to_drop)\n",
    "target = target.drop(rows_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:41.758746Z",
     "iopub.status.busy": "2025-04-20T14:22:41.758497Z",
     "iopub.status.idle": "2025-04-20T14:22:41.776175Z",
     "shell.execute_reply": "2025-04-20T14:22:41.775259Z",
     "shell.execute_reply.started": "2025-04-20T14:22:41.758727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode compound types\n",
    "lapData['Compound'] = lapData['Compound'].astype('category').cat.codes\n",
    "\n",
    "# Convert relevant columns into categorical data types.\n",
    "lapData['Position'] = lapData['Position'].astype('category')\n",
    "lapData['Compound'] = lapData['Compound'].astype('category')\n",
    "lapData['Rainfall'] = lapData['Rainfall'].astype('category')\n",
    "\n",
    "lapData = lapData.drop(columns=['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "We train a Random Forest Classifier to predict the target variable based on the prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:41.777635Z",
     "iopub.status.busy": "2025-04-20T14:22:41.777088Z",
     "iopub.status.idle": "2025-04-20T14:22:41.902060Z",
     "shell.execute_reply": "2025-04-20T14:22:41.901139Z",
     "shell.execute_reply.started": "2025-04-20T14:22:41.777605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       361\n",
      "           1       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.99       369\n",
      "   macro avg       0.85      0.81      0.83       369\n",
      "weighted avg       0.99      0.99      0.99       369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, max_depth = 10, min_samples_split = 2, n_estimators = 50, class_weight='balanced')\n",
    "\n",
    "# Split data into training and test sets (80/20 split).\n",
    "lapData_train, lapData_test, target_train, target_test = train_test_split(lapData, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "model.fit(lapData_train, target_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(lapData_test)\n",
    "\n",
    "# Classification report \n",
    "print(\"\\nClassification Report:\\n\", classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Strategy Assistant\n",
    "\n",
    "## Get set up\n",
    "\n",
    "Start by installing and importing the LangGraph SDK and LangChain support for the Gemini API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:41.905451Z",
     "iopub.status.busy": "2025-04-20T14:22:41.905131Z",
     "iopub.status.idle": "2025-04-20T14:22:50.023450Z",
     "shell.execute_reply": "2025-04-20T14:22:50.022405Z",
     "shell.execute_reply.started": "2025-04-20T14:22:41.905423Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping libpysal as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping thinc as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping spacy as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping fastai as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping ydata-profiling as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping google-cloud-bigquery as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping google-generativeai as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Remove conflicting packages from the Kaggle base environment.\n",
    "!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n",
    "# Install langgraph and the packages used in this lab.\n",
    "!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:50.025130Z",
     "iopub.status.busy": "2025-04-20T14:22:50.024792Z",
     "iopub.status.idle": "2025-04-20T14:22:50.169062Z",
     "shell.execute_reply": "2025-04-20T14:22:50.168382Z",
     "shell.execute_reply.started": "2025-04-20T14:22:50.025104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define core instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:50.170128Z",
     "iopub.status.busy": "2025-04-20T14:22:50.169850Z",
     "iopub.status.idle": "2025-04-20T14:22:50.181540Z",
     "shell.execute_reply": "2025-04-20T14:22:50.180802Z",
     "shell.execute_reply.started": "2025-04-20T14:22:50.170107Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import json\n",
    "import atexit\n",
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Display utilities\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# LangGraph core\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# LangChain Google Generative AI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "  \n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Race State and Assistant Instructions\n",
    "Set up the race state structure and system prompt that guides how the assistant interacts during the race. Includes examples of expected behavior and tool usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:50.183200Z",
     "iopub.status.busy": "2025-04-20T14:22:50.182819Z",
     "iopub.status.idle": "2025-04-20T14:22:50.200878Z",
     "shell.execute_reply": "2025-04-20T14:22:50.199896Z",
     "shell.execute_reply.started": "2025-04-20T14:22:50.183176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class RaceState(TypedDict):\n",
    "    \"\"\"State representing the human startegies's pit stop conversation.\"\"\"\n",
    "\n",
    "    # The chat conversation. This preserves the conversation history\n",
    "    # between nodes. The `add_messages` annotation indicates to LangGraph\n",
    "    # that state is updated by appending returned messages, not replacing\n",
    "    # them.\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "    # Number of laps in the race\n",
    "    total_lap_number: float\n",
    "\n",
    "    # The state of the track\n",
    "    # {'Green', 'Safety Car', 'Virtual Safety Car'}\n",
    "    track_status: float\n",
    "    \n",
    "    # Weather data\n",
    "    # [track_temp, rainfall]\n",
    "    weather: list[float]\n",
    "\n",
    "    # Log of lap information and related pit decisions\n",
    "    lap: list[dict]\n",
    "\n",
    "    # Flag indicating that the race is over.\n",
    "    finished: bool\n",
    "\n",
    "\n",
    "# System prompt guiding the assistant’s behavior during the race\n",
    "STRATEGYASSISTAN_SYSINT = (\n",
    "    \"system\", \n",
    "\n",
    "    \"\"\"\n",
    "    You are an AI race strategist assistant helping a human strategist during a Grand Prix. \n",
    "    Your task is to decide whether the car should pit for new tyres based on live race data.  \n",
    "    \n",
    "    A human strategist will give you the necessary lap and weather information throughout the race. \n",
    "    You must tell them if they should BOX, BOX or STAY OUT this lap, and provide a confidence percentage and a brief explanation of the decision — but nothing more.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Tools & Instructions\n",
    "    \n",
    "    - At the start of the race, the human will give you:\n",
    "        - Total number of laps → store this using `store_total_lap_number`\n",
    "        - Track status → store using `store_track_status`  \n",
    "        - weather: track temperature and if there is rain or not → store and update using `update_weather`\n",
    "    \n",
    "    - Throughout the race:\n",
    "        - Make sure you have the the waethr condition, track status and total number of laps before calling `pit_check`\n",
    "        - You can update the track temperature and if it reains or not using `update_weather`\n",
    "        - When you get lap information use `pit_check` to get decision if to pit or not\n",
    "        - Retrieve total number of laps using `get_total_lap_number`\n",
    "        - Retrieve track status using `get_track_status`\n",
    "        - Retrieve weather weather information using `get_weather`\n",
    "      \n",
    "    \n",
    "    If a required tool has not yet been implemented, you are allowed to break the fourth wall and tell the human strategist:  \n",
    "    \"This tool is not yet implemented.\"\n",
    "\n",
    "    \n",
    "    Here are four examples demonstrating the expected input, model output, and reply style:\n",
    "    \n",
    "    Example 1 – Pit under normal conditions:  \n",
    "\n",
    "    Human input:\n",
    "    We’re on lap 21, currently P3, running 20-lap-old Mediums. \n",
    "    Our lap delta is -0.13, the gap to the car ahead is 5.97 seconds, and if we box now, we’ll lose 7 positions.\n",
    "\n",
    "    Respons:  \n",
    "    Pit, confidence 76%. \n",
    "    Reason: BOX, BOX. \\n Tyres are reaching the end of their performance window. Pitting now helps minimize position loss before others stop.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Example 2 – Pit in wet conditions:  \n",
    "    Human input:\n",
    "    Lap 44. P1. 10-lap Hards. Rain started. Delta +1.2. Gap 0. Lose 3 if we pit. 42 to go.\n",
    "    \n",
    "    Respons:  \n",
    "    Pit, confidence 91%.\n",
    "    Reason: BOX, BOX. \\n Rain is affecting grip, and loss is acceptable given 42 laps remaining.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Example 3 – Stay out under Safety Car:  \n",
    "    Human input:\n",
    "    Lap 3, P5. Safety Car. Mediums, 2 laps. Gap 1.3, delta -0.1. Pit drops us 5. 55 left.\n",
    "    \n",
    "    Reply:  \n",
    "    Stay out, confidence 80%. \n",
    "    Reason: STAY OUT. \\n It’s early in the race and tyres are fresh. Pitting now would lose positions without strategic advantage.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Example 4 – Stay out late in race: \n",
    "    Human input:\n",
    "    We're on lap 46, running P6. Tyres are 20-lap-old hards, still holding up. \n",
    "    Gap to car ahead is 2.2, delta's -0.3. If we pit, we lose 2 spots. Only 7 laps left.\n",
    "    \n",
    "    Reply:  \n",
    "    Stay out, confidence 84%. \n",
    "    Reason: STAY OUT. \\n Tyres are holding up and pitting now would cost positions without meaningful advantage.\n",
    "\n",
    "    \"\"\",\n",
    "\n",
    ")\n",
    "\n",
    "# Message with which the system opens the conversation.\n",
    "WELCOME_MSG = \"Hey, I am your Strategy Assistent, and I will be here to help during the Saudi Arabian GP. \\n Please give me the number of laps in this race.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tools\n",
    "\n",
    "These tools let the assistant store and retrieve race data (like total laps, track status, weather) and use it to decide if the car should pit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:50.202269Z",
     "iopub.status.busy": "2025-04-20T14:22:50.201911Z",
     "iopub.status.idle": "2025-04-20T14:22:50.246668Z",
     "shell.execute_reply": "2025-04-20T14:22:50.245677Z",
     "shell.execute_reply.started": "2025-04-20T14:22:50.202248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def store_total_lap_number(total_lap_number: float) -> str:\n",
    "    \"\"\"Stors the total number of laps in the race\n",
    "    \n",
    "    Returns:\n",
    "        Confirmation message \n",
    "    \"\"\"\n",
    "\n",
    "@tool\n",
    "def get_total_lap_number() -> str:\n",
    "    \"\"\"Returns the total number of laps in the race\"\"\"\n",
    "\n",
    "@tool\n",
    "def store_track_status(track_status: str) -> str:\n",
    "    \"\"\"Store the current track status (Green, Safety Car, Virtual Safety Car)   \n",
    "    \n",
    "    Returns:\n",
    "        Confirmation message \n",
    "    \"\"\"\n",
    "\n",
    "@tool\n",
    "def get_track_status() -> str:\n",
    "    \"\"\"Return the current track status\"\"\"\n",
    "\n",
    "@tool\n",
    "def update_weather(track_temp: float, rainfall: float) -> str:\n",
    "    \"\"\"Update the current weather conditions\n",
    "\n",
    "    Returns:\n",
    "        Confirmation message.\n",
    "    \"\"\"\n",
    "    \n",
    "@tool\n",
    "def get_weather() -> str:\n",
    "    \"\"\"Returns the latest weather conditions\"\"\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def pit_check(lap_number: float, position: float, tyre_life: float, compound: str, delta_time: float, gap_ahead: float, pos_to_lose: float) -> [float]:\n",
    "    \"\"\"Pass lap and race conditions to the model and get a pit decision\n",
    "\n",
    "    Returns:\n",
    "        Model prediction and confidence\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define control flow and race logic\n",
    "\n",
    "This section connects the model, tools, and human input. \n",
    "It routes messages between the user, the AI, and the tools. \n",
    "It also defines how race data is processed and stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:50.248060Z",
     "iopub.status.busy": "2025-04-20T14:22:50.247714Z",
     "iopub.status.idle": "2025-04-20T14:22:50.303794Z",
     "shell.execute_reply": "2025-04-20T14:22:50.302991Z",
     "shell.execute_reply.started": "2025-04-20T14:22:50.248030Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def race_node(state: RaceState) -> RaceState:\n",
    "    \"\"\"Processes tool calls and updates race state.\"\"\"\n",
    "    \n",
    "    tool_msg = state.get(\"messages\", [])[-1]\n",
    "    total_lap_number = state.get(\"total_lap_number\", [])\n",
    "    track_status = state.get(\"track_status\", [])\n",
    "    weather = state.get(\"weather\", [])\n",
    "    lap = state.get(\"lap\",[])\n",
    "    outbound_msgs = []\n",
    "    lap_log = state.get(\"log\",[])\n",
    "    race_finished = False\n",
    "\n",
    "    for tool_call in tool_msg.tool_calls:\n",
    "        if tool_call[\"name\"] == \"store_total_lap_number\":\n",
    "            total_lap_number = f'{tool_call[\"args\"][\"total_lap_number\"]}'\n",
    "            response = '\\n'.join(total_lap_number)\n",
    "            \n",
    "        elif tool_call[\"name\"] ==\"get_total_lap_number\":\n",
    "            response = \"\\n\".join(total_lap_number) if total_lap_number else \"No total lap number\"\n",
    "\n",
    "        elif tool_call[\"name\"] == \"store_track_status\":\n",
    "            track_status = f'{tool_call[\"args\"][\"track_status\"]}'\n",
    "            response = '\\n'.join(track_status)\n",
    "            \n",
    "        elif tool_call[\"name\"] ==\"get_track_status\":\n",
    "            response = \"\\n\".join(track_status) if track_status else \"No track infomration\"\n",
    "\n",
    "        elif tool_call[\"name\"] == \"update_weather\":\n",
    "            weather = (f'{tool_call[\"args\"][\"track_temp\"]}, {tool_call[\"args\"][\"rainfall\"]}')\n",
    "            response = \"\\n\".join(weather)\n",
    "\n",
    "            \n",
    "        elif tool_call[\"name\"] == \"get_weather\":\n",
    "            response = \"\\n\".join(weather) if weather else \"No weather data\"\n",
    "            \n",
    "        \n",
    "        elif tool_call[\"name\"] == \"pit_check\":\n",
    "            # Extract inputs\n",
    "            lap_number = int(tool_call[\"args\"][\"lap_number\"])\n",
    "            position = tool_call[\"args\"][\"position\"]\n",
    "            tyre_life = float(tool_call[\"args\"][\"tyre_life\"])\n",
    "            delta_time = tool_call[\"args\"][\"delta_time\"]\n",
    "            gap_ahead = tool_call[\"args\"][\"gap_ahead\"]\n",
    "            pos_to_lose = tool_call[\"args\"][\"pos_to_lose\"]\n",
    "            total_laps = float(total_lap_number)\n",
    "            remaining_laps = total_laps - lap_number\n",
    "\n",
    "            # Convert compound to numeric value\n",
    "            compound_str = tool_call[\"args\"][\"compound\"]\n",
    "            compound_value = (\n",
    "                2.0 if compound_str in [\"Medium\", \"Mediums\"] else\n",
    "                3.0 if compound_str in [\"Soft\", \"Softs\"] else\n",
    "                1.0 if compound_str in [\"Intermediates\", \"Inters\"] else\n",
    "                4.0 if compound_str in [\"Wet\", \"Wets\"] else\n",
    "                0.0\n",
    "            )\n",
    "\n",
    "            # Convert track status to numeric value\n",
    "            track_status_value = (\n",
    "                1.0 if track_status == \"Safety Car\" else\n",
    "                2.0 if track_status == \"Virtual Safety Car\" else\n",
    "                0.0\n",
    "            )\n",
    "\n",
    "            # Parse weather info\n",
    "            weather_data = weather.split(\",\")\n",
    "            track_temp = float(weather_data[0].strip())\n",
    "            rainfall = float(weather_data[1].strip())\n",
    "            \n",
    "            # Create lap feature vector\n",
    "            lap_data = {\n",
    "                \"LapNumber\": lap_number,\n",
    "                \"Position\": position,\n",
    "                \"Compound\": compound_value,\n",
    "                \"TyreLife\": tyre_life,\n",
    "                \"TrackStatus\": track_status_value,\n",
    "                \"TrackTemp\": track_temp,\n",
    "                \"Rainfall\": rainfall,\n",
    "                \"DeltaTime\": delta_time,\n",
    "                \"GapAhead\": gap_ahead,\n",
    "                \"PosToLose\": pos_to_lose,\n",
    "                \"TotalLaps\": total_laps,\n",
    "                \"RemainingLaps\": remaining_laps\n",
    "            }\n",
    "            \n",
    "            # Run prediction\n",
    "            model_prediction_proba = model.predict_proba(pd.DataFrame([lap_data]))\n",
    "\n",
    "            if model_prediction_proba[0,1] >= 75:\n",
    "                lap_data[\"Decision\"] = \"BOX BOX\"\n",
    "                lap_data[\"Confidence\"] = float(model_prediction_proba[0][1])\n",
    "                response = \"\\n\".join(f'Stay out, confidence {model_prediction_proba[0][1]}')\n",
    "            else:\n",
    "                lap_data[\"Decision\"] = \"STAY OUT\"\n",
    "                lap_data[\"Confidence\"] = float(model_prediction_proba[0][0])\n",
    "                response = \"\\n\".join(f'Stay out, confidence {model_prediction_proba[0][0]}')\n",
    "\n",
    "            \n",
    "            lap.append(OrderedDict(lap_data))\n",
    "            \n",
    "        else:\n",
    "            raise NotImplementedError(f'Unknown tool call: {tool_call[\"name\"]}')\n",
    "\n",
    "        # Record tool call response\n",
    "        outbound_msgs.append(\n",
    "            ToolMessage(\n",
    "                content=response,\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"messages\": outbound_msgs,\n",
    "        \"track_status\": track_status,\n",
    "        \"weather\": weather,\n",
    "        \"total_lap_number\": total_lap_number,\n",
    "        \"lap\": lap,\n",
    "        \"finished\": race_finished\n",
    "        }\n",
    "\n",
    "\n",
    "def human_node(state: RaceState) -> RaceState:\n",
    "    \"\"\"Displays model output and waits for human input.\"\"\"\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    print(\"Model:\", last_msg.content)\n",
    "\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # End session if user types a quit keyword\n",
    "    if user_input in {\"q\", \"quit\", \"exit\"}:\n",
    "        state[\"finished\"] = True\n",
    "\n",
    "    return state | {\"messages\": [(\"user\", user_input)]}\n",
    "    \n",
    "\n",
    "def maybe_exit_human_node(state: RaceState) -> Literal[\"chatbot\", \"__end__\"]:\n",
    "    \"\"\"Route to chatbot or end based on user input.\"\"\"\n",
    "    return END if state.get(\"finished\", False) else \"chatbot\"\n",
    "\n",
    "\n",
    "def chatbot(state: RaceState) -> RaceState:\n",
    "    \"\"\"Main chatbot logic including tool calls.\"\"\"\n",
    "    defaults = {\"race_info\": [], \"finished\": False}\n",
    "\n",
    "    if state[\"messages\"]:\n",
    "        new_output = llm_with_tools.invoke([STRATEGYASSISTAN_SYSINT] + state[\"messages\"])\n",
    "    else:\n",
    "        new_output = AIMessage(content=WELCOME_MSG)\n",
    "\n",
    "    return defaults | state | {\"messages\": [new_output]}\n",
    "\n",
    "\n",
    "def maybe_route_to_tools(state: RaceState) -> str:\n",
    "    \"\"\"Route to the correct next node depending on the message type.\"\"\"\n",
    "    if not (msgs := state.get(\"messages\", [])):\n",
    "        raise ValueError(f\"No messages found when parsing state: {state}\")\n",
    "\n",
    "    msg = msgs[-1]\n",
    "\n",
    "    if state.get(\"finished\", False):\n",
    "        return END\n",
    "\n",
    "    elif hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n",
    "        return \"racing\"\n",
    "    else:\n",
    "        return \"human\"\n",
    "\n",
    "\n",
    "# Define the app graph\n",
    "graph_builder = StateGraph(RaceState)\n",
    "\n",
    "# Tool list\n",
    "race_tools = [\n",
    "    store_total_lap_number,\n",
    "    get_total_lap_number,\n",
    "    store_track_status,\n",
    "    get_track_status,\n",
    "    update_weather,\n",
    "    get_weather,\n",
    "    pit_check\n",
    "]\n",
    "\n",
    "# Bind tools to the model\n",
    "llm_with_tools = llm.bind_tools(race_tools)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "graph_builder.add_node(\"racing\", race_node)\n",
    "\n",
    "# Set flow logic\n",
    "graph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\n",
    "graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"racing\", \"chatbot\")\n",
    "\n",
    "# Final app\n",
    "chat_with_human= graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Strategy Assistent\n",
    "\n",
    "To run the agent, you need to uncomment the `.invoke(...)` line in the code. \n",
    "This line has been commented out in the notebook to make it self-contained for initial setup. Once you’re ready to run the agent, simply remove the comment to enable the execution of the model.\n",
    "\n",
    "Additionally, a few examples of human input have been provided in the comments following that line. These examples simulate real-world race data and help evaluate the agent’s performance during testing.\n",
    "\n",
    "Disclaimer:\n",
    "The model’s performance on race data from other seasons may be suboptimal, likely due to missing contextual features that influence real-world strategy decisions. However, for the purpose of this project—demonstrating the capabilities of a GenAI-powered agent—the current performance is sufficient. Improving the model's accuracy by incorporating additional features is part of planned future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:50.305531Z",
     "iopub.status.busy": "2025-04-20T14:22:50.304778Z",
     "iopub.status.idle": "2025-04-20T14:22:50.310925Z",
     "shell.execute_reply": "2025-04-20T14:22:50.309926Z",
     "shell.execute_reply.started": "2025-04-20T14:22:50.305503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "config = {\"recursion_limit\": 100}\n",
    "\n",
    "# Remember that this will loop forever, unless you input \"q\", \"quit\" or \"exit\"\n",
    "\n",
    "\n",
    "# Uncomment this line to execute the graph:\n",
    "# state = chat_with_human.invoke({\"messages\": []}, config)\n",
    "\n",
    "\n",
    "# example 1:\n",
    "# Model: Hey, I am your Strategy Assistent, and I will be here to help during the Saudi Arabian GP. Please give me the number of laps in this race.\n",
    "\n",
    "# User:  50 laps\n",
    "# User:  safety care is out, track temp 34, no rain\n",
    "# Used: we are p1 on lap 3, 2 lap old soft tyres, gap to driver ahead 0.8, delta -1.6, losing 13 position if we pit\n",
    "# Expected answer: STAY OUT\n",
    "\n",
    "\n",
    "# example 2:\n",
    "# User:  race has 50 laps\n",
    "# User:  track is green, track temp 31.8, no rain\n",
    "# User: lap 16 p7. 15 lap old hards delta 2.358, gap ahread 0.336196 would lose 2\n",
    "# Expected answer: BOX BOX\n",
    "\n",
    "\n",
    "# example 3:\n",
    "# User:  50 laps\n",
    "# User:  track is green, track temp 28.3, no rain\n",
    "# User:  lap 15, position 6, 14 laps old mediums, delta -0.19, gap ahead 0.97, losing 4 positions\n",
    "# Expected answer: STAY OUT\n",
    "\n",
    "# User:  lap 16, position 5, 15 laps old mediums, delta -0.15, gap ahead 1.1, losing 5 positions\n",
    "# Expected answer: Either decision wuld be acceptable\n",
    "\n",
    "# User:  lpa 17 p 2 16 used medium, delta -0.10, gap ahead 1.6, losing 4 positions\n",
    "# Expected answer: BOX BOX\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 💾 Saving the Agent Decision Log as a JSON File\n",
    "\n",
    "The `lap_log` stores all relevant race information and the agent’s decisions across multiple laps.  \n",
    "Saving it as a `.json` file allows us to easily review the model's performance after a race simulation.  \n",
    "This helps us better understand the models’s behavior, evaluate its decision-making, and identify areas for future improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:22:50.312102Z",
     "iopub.status.busy": "2025-04-20T14:22:50.311841Z",
     "iopub.status.idle": "2025-04-20T14:22:50.329174Z",
     "shell.execute_reply": "2025-04-20T14:22:50.328320Z",
     "shell.execute_reply.started": "2025-04-20T14:22:50.312070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"lapLog.json\", \"w\") as f:\n",
    "    json.dump(state['lap'], f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This project demonstrates the potential of GenAI to assist Formula 1 strategists in making critical pit stop decisions during live races. By leveraging race data such as lap number, tyre conditions, track status, and more, the GenAI assistant offers timely, data-driven recommendations on whether to pit or stay out.\n",
    "\n",
    "## GenAI Capabilities Used:\n",
    "\n",
    "- **Agents**: The core of this project is built around a GenAI-powered agent that functions as a \"Pit Wall Assistant.\" This agent processes real-time race data and outputs recommendations based on learned patterns.\n",
    "\n",
    "- **Few-Shot Prompting**: Through the use of few-shot prompting, the model learns from limited input examples, showcasing how it can adapt to specific race scenarios and provide contextual recommendations.\n",
    "\n",
    "- **Grounding**: The assistant's decisions are grounded in real race data, ensuring that predictions align with real-world scenarios and provide value to the strategist in the heat of the moment.\n",
    "\n",
    "- **Structured Output/JSON Mode**: The assistant generates structured JSON outputs, making it easy to evaluate adn improve the predictionmodel as well as make it easy for the startegyst to ahve a look back at the decisions made after the race.\n",
    "\n",
    "\n",
    "While the primary focus was on building and demonstrating the GenAI agent, future work will aim to improve model performance, particularly by incorporating additional contextual features and optimizing decision-making in varied and complex race conditions.\n",
    "\n",
    "By reducing the cognitive load of strategists, this GenAI assistant enhances their ability to focus on higher-level decisions while leaving number-driven tasks to the AI, thus improving overall race strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "While the current GenAI-powered Pit Wall Assistant offers valuable support for Formula 1 strategists, there are several areas for improvement and expansion. The following outlines potential directions for future work:\n",
    "\n",
    "### 1. **Enhanced Model Performance**\n",
    "   - **Feature Expansion**: The current model's performance could be improved by incorporating additional race-related features such as pit stop windo, available tyres, real-time telemetry data (e.g., lap times, sector times, driver behavior) and others. Including more features would provide the model with a more comprehensive understanding of the race dynamics and improve decision-making.\n",
    "   - **Alternative Models**: Exploring other machine learning models, such as deep learning-based architectures or ensemble methods, could potentially enhance the predictive power and accuracy of the assistant. This would also involve hyperparameter tuning and cross-validation to optimize the model's generalization across different race scenarios.\n",
    "\n",
    "### 2. **Integration with Real-Time Race Data**\n",
    "   - The assistant currently operates with static, pre-loaded race data. For real-world applications, integrating the assistant with live race feeds and telemetry would allow it to provide real-time decision-making assistance. This could involve real-time data ingestion from sensors, GPS, and communication systems within F1 teams.\n",
    "\n",
    "### 3. **Context-Aware Decision Making**\n",
    "   - The current model generates pit recommendations based purely on numerical inputs. Future iterations could incorporate more nuanced decision-making capabilities by integrating psychological factors and strategic insights from human race engineers. For example, AI could provide insights based on how competitors are performing and suggest strategies to counter specific drivers' behavior.\n",
    "\n",
    "### 4. **Adaptive Strategies for Different Circuits**\n",
    "   - Currently, the model is trained on a limited number of circuits. Expanding the dataset to include more tracks, particularly those with different weather conditions and layouts, will enable the assistant to adapt its recommendations to a wider range of environments. This would improve its utility across the entire F1 season and make it more versatile.\n",
    "\n",
    "### 5. **Human-AI Collaboration**\n",
    "   - Another key area of future work is improving the collaboration between human strategists and the AI. The assistant can be designed to generate multiple strategies or alternatives, allowing the strategist to select the best option based on their judgment and knowledge of the race. This human-AI synergy could lead to more effective decision-making and better outcomes.\n",
    "\n",
    "By addressing these areas, the GenAI-powered Pit Wall Assistant can be refined into a more powerful, reliable, and adaptable tool that provides substantial support to F1 strategists, ultimately enhancing race strategies and decision-making.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
